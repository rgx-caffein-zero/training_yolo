{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seal Detection - Test & Visualization\n",
    "\n",
    "シール検出のテストと可視化を行うノートブック\n",
    "\n",
    "## 機能\n",
    "- 画像/動画からの検出テスト\n",
    "- 検出結果の可視化\n",
    "- バッチ処理\n",
    "- 出力動画の生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML, Video\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# matplotlibの設定\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [14, 8]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# 検出器のインポート\n",
    "import sys\n",
    "sys.path.append('/workspace/scripts')\n",
    "\n",
    "from color_shape_detector import ColorShapeDetector, Detection\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 検出器の初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定ファイルのパス\n",
    "CONFIG_PATH = '/workspace/scripts/detector_config.yaml'\n",
    "\n",
    "# 検出器を初期化\n",
    "detector = ColorShapeDetector(CONFIG_PATH)\n",
    "\n",
    "# 現在の設定を表示\n",
    "print(\"Current Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(yaml.dump(detector.config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 画像からの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_show(image_path, detector, show_masks=True):\n",
    "    \"\"\"\n",
    "    画像から検出して結果を表示\n",
    "    \"\"\"\n",
    "    # 画像読み込み\n",
    "    frame = cv2.imread(image_path)\n",
    "    if frame is None:\n",
    "        print(f\"✗ Cannot read: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Image: {image_path}\")\n",
    "    print(f\"Size: {frame.shape[1]}x{frame.shape[0]}\")\n",
    "    \n",
    "    # 検出実行\n",
    "    start_time = time.time()\n",
    "    detections = detector.detect(frame)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Detection time: {elapsed*1000:.1f}ms\")\n",
    "    print(f\"Found {len(detections)} objects\")\n",
    "    \n",
    "    # 結果描画\n",
    "    result = detector.draw_detections(frame, detections, draw_hull=True, draw_vertices=True)\n",
    "    \n",
    "    # 表示\n",
    "    if show_masks:\n",
    "        masks = detector.get_debug_masks(frame)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        axes[0, 0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        axes[0, 0].set_title('Original')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        axes[0, 1].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        axes[0, 1].set_title(f'Detection Result ({len(detections)} objects)')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        axes[1, 0].imshow(masks['blue'], cmap='Blues')\n",
    "        axes[1, 0].set_title('Blue Mask')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        axes[1, 1].imshow(masks['yellow'], cmap='YlOrBr')\n",
    "        axes[1, 1].set_title('Yellow Mask')\n",
    "        axes[1, 1].axis('off')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        axes[0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title(f'Detection Result ({len(detections)} objects)')\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 検出結果の詳細\n",
    "    if detections:\n",
    "        print(\"\\n検出結果の詳細:\")\n",
    "        print(\"-\" * 60)\n",
    "        for i, det in enumerate(detections, 1):\n",
    "            x, y, w, h = det.bbox\n",
    "            print(f\"{i}. {det.class_name}\")\n",
    "            print(f\"   Position: ({x}, {y})\")\n",
    "            print(f\"   Size: {w}x{h}\")\n",
    "            print(f\"   Vertices: {det.vertices}\")\n",
    "            print(f\"   Confidence: {det.confidence:.3f}\")\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 画像パスを指定して検出テスト ===\n",
    "IMAGE_PATH = \"/workspace/videos/sample.jpg\"  # ← ここを変更\n",
    "\n",
    "detections = detect_and_show(IMAGE_PATH, detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 動画からの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_jupyter(\n",
    "    video_path,\n",
    "    output_path,\n",
    "    detector,\n",
    "    sample_interval=30,\n",
    "    show_samples=5\n",
    "):\n",
    "    \"\"\"\n",
    "    動画を処理して出力動画を生成\n",
    "    \n",
    "    Args:\n",
    "        video_path: 入力動画パス\n",
    "        output_path: 出力動画パス\n",
    "        detector: 検出器\n",
    "        sample_interval: サンプル表示の間隔\n",
    "        show_samples: 表示するサンプル数\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"✗ Cannot open: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # 動画情報\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video: {video_path}\")\n",
    "    print(f\"Resolution: {width}x{height}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"Duration: {total_frames/fps:.1f}s\")\n",
    "    \n",
    "    # 出力設定\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # 統計\n",
    "    detection_counts = {'blue_triangle': 0, 'yellow_octagon': 0}\n",
    "    sample_frames = []\n",
    "    sample_results = []\n",
    "    \n",
    "    # 処理\n",
    "    frame_count = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for _ in tqdm(range(total_frames), desc=\"Processing\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # 検出\n",
    "        start_time = time.time()\n",
    "        detections = detector.detect(frame)\n",
    "        elapsed = time.time() - start_time\n",
    "        total_time += elapsed\n",
    "        \n",
    "        # 統計更新\n",
    "        for det in detections:\n",
    "            if det.class_name in detection_counts:\n",
    "                detection_counts[det.class_name] += 1\n",
    "        \n",
    "        # 描画\n",
    "        result = detector.draw_detections(frame, detections, draw_hull=True)\n",
    "        \n",
    "        # FPS表示\n",
    "        current_fps = 1.0 / elapsed if elapsed > 0 else 0\n",
    "        cv2.putText(result, f\"FPS: {current_fps:.1f}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # 書き込み\n",
    "        writer.write(result)\n",
    "        \n",
    "        # サンプル保存\n",
    "        if frame_count % sample_interval == 0 and len(sample_frames) < show_samples:\n",
    "            sample_frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            sample_results.append(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    \n",
    "    # 結果表示\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Processing Complete!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Processed frames: {frame_count}\")\n",
    "    print(f\"Average FPS: {frame_count/total_time:.2f}\")\n",
    "    print(f\"Output: {output_path}\")\n",
    "    print(f\"\\nDetection counts:\")\n",
    "    for name, count in detection_counts.items():\n",
    "        print(f\"  - {name}: {count}\")\n",
    "    \n",
    "    # サンプル表示\n",
    "    if sample_frames:\n",
    "        print(f\"\\nSample frames (every {sample_interval} frames):\")\n",
    "        \n",
    "        n_samples = len(sample_frames)\n",
    "        fig, axes = plt.subplots(2, n_samples, figsize=(4*n_samples, 8))\n",
    "        \n",
    "        if n_samples == 1:\n",
    "            axes = axes.reshape(2, 1)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            axes[0, i].imshow(sample_frames[i])\n",
    "            axes[0, i].set_title(f'Frame {(i+1)*sample_interval}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            axes[1, i].imshow(sample_results[i])\n",
    "            axes[1, i].set_title('Detection')\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return detection_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 動画処理（必要に応じてコメント解除）===\n",
    "# VIDEO_INPUT = \"/workspace/videos/input.mp4\"\n",
    "# VIDEO_OUTPUT = \"/workspace/videos/output.mp4\"\n",
    "\n",
    "# process_video_jupyter(VIDEO_INPUT, VIDEO_OUTPUT, detector, sample_interval=100, show_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. インタラクティブなフレーム選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFrameExplorer:\n",
    "    \"\"\"動画フレームをインタラクティブに探索\"\"\"\n",
    "    \n",
    "    def __init__(self, video_path, detector):\n",
    "        self.video_path = video_path\n",
    "        self.detector = detector\n",
    "        \n",
    "        # 動画を開く\n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(f\"Cannot open: {video_path}\")\n",
    "        \n",
    "        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        self.fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # UI\n",
    "        self.frame_slider = widgets.IntSlider(\n",
    "            value=0, min=0, max=self.total_frames-1,\n",
    "            description='Frame:',\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        self.frame_slider.observe(self._on_frame_change, names='value')\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        print(f\"Video: {video_path}\")\n",
    "        print(f\"Frames: {self.total_frames}, FPS: {self.fps}\")\n",
    "    \n",
    "    def _on_frame_change(self, change):\n",
    "        self._show_frame(change['new'])\n",
    "    \n",
    "    def _show_frame(self, frame_num):\n",
    "        with self.output:\n",
    "            clear_output = True\n",
    "            from IPython.display import clear_output\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # フレーム読み込み\n",
    "            self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = self.cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                print(f\"Cannot read frame {frame_num}\")\n",
    "                return\n",
    "            \n",
    "            # 検出\n",
    "            detections = self.detector.detect(frame)\n",
    "            result = self.detector.draw_detections(frame, detections, draw_hull=True, draw_vertices=True)\n",
    "            \n",
    "            # 表示\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "            \n",
    "            axes[0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            axes[0].set_title(f'Frame {frame_num} (Time: {frame_num/self.fps:.2f}s)')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            axes[1].imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "            axes[1].set_title(f'Detection ({len(detections)} objects)')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 検出情報\n",
    "            if detections:\n",
    "                for det in detections:\n",
    "                    print(f\"  • {det.class_name}: bbox={det.bbox}, conf={det.confidence:.2f}\")\n",
    "    \n",
    "    def display(self):\n",
    "        display(widgets.VBox([self.frame_slider, self.output]))\n",
    "        self._show_frame(0)\n",
    "    \n",
    "    def close(self):\n",
    "        self.cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === インタラクティブフレーム探索（必要に応じてコメント解除）===\n",
    "# VIDEO_PATH = \"/workspace/videos/input.mp4\"\n",
    "# explorer = VideoFrameExplorer(VIDEO_PATH, detector)\n",
    "# explorer.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. バッチ処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_detect(image_dir, detector, output_dir=None):\n",
    "    \"\"\"\n",
    "    ディレクトリ内の全画像を処理\n",
    "    \"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "    \n",
    "    image_files = [f for f in image_dir.iterdir() \n",
    "                   if f.suffix.lower() in image_extensions]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {image_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images\")\n",
    "    \n",
    "    # 出力ディレクトリ\n",
    "    if output_dir:\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 結果\n",
    "    results = []\n",
    "    \n",
    "    for img_path in tqdm(image_files, desc=\"Processing\"):\n",
    "        frame = cv2.imread(str(img_path))\n",
    "        if frame is None:\n",
    "            continue\n",
    "        \n",
    "        detections = detector.detect(frame)\n",
    "        \n",
    "        results.append({\n",
    "            'file': img_path.name,\n",
    "            'detections': len(detections),\n",
    "            'blue_triangle': sum(1 for d in detections if d.class_name == 'blue_triangle'),\n",
    "            'yellow_octagon': sum(1 for d in detections if d.class_name == 'yellow_octagon'),\n",
    "        })\n",
    "        \n",
    "        # 結果を保存\n",
    "        if output_dir and detections:\n",
    "            result_frame = detector.draw_detections(frame, detections, draw_hull=True)\n",
    "            output_path = output_dir / f\"detected_{img_path.name}\"\n",
    "            cv2.imwrite(str(output_path), result_frame)\n",
    "    \n",
    "    # 統計表示\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Batch Processing Results\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_blue = sum(r['blue_triangle'] for r in results)\n",
    "    total_yellow = sum(r['yellow_octagon'] for r in results)\n",
    "    \n",
    "    print(f\"Total images: {len(results)}\")\n",
    "    print(f\"Total blue_triangle: {total_blue}\")\n",
    "    print(f\"Total yellow_octagon: {total_yellow}\")\n",
    "    \n",
    "    # 検出があった画像のみ表示\n",
    "    detected = [r for r in results if r['detections'] > 0]\n",
    "    print(f\"\\nImages with detections: {len(detected)}\")\n",
    "    for r in detected[:10]:  # 最初の10件\n",
    "        print(f\"  {r['file']}: {r['blue_triangle']} blue, {r['yellow_octagon']} yellow\")\n",
    "    \n",
    "    if len(detected) > 10:\n",
    "        print(f\"  ... and {len(detected) - 10} more\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === バッチ処理（必要に応じてコメント解除）===\n",
    "# IMAGE_DIR = \"/workspace/dataset/raw_images\"\n",
    "# OUTPUT_DIR = \"/workspace/dataset/detected\"\n",
    "# results = batch_detect(IMAGE_DIR, detector, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 結果画像の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_detection_result(image_path, output_path, detector):\n",
    "    \"\"\"\n",
    "    検出結果を画像として保存\n",
    "    \"\"\"\n",
    "    frame = cv2.imread(image_path)\n",
    "    if frame is None:\n",
    "        print(f\"Cannot read: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    detections = detector.detect(frame)\n",
    "    result = detector.draw_detections(frame, detections, draw_hull=True, draw_vertices=True)\n",
    "    \n",
    "    cv2.imwrite(output_path, result)\n",
    "    print(f\"✓ Saved: {output_path}\")\n",
    "    print(f\"  Detections: {len(detections)}\")\n",
    "    \n",
    "    # 表示\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Detection Result ({len(detections)} objects)')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 結果を保存（必要に応じてコメント解除）===\n",
    "# save_detection_result(\n",
    "#     \"/workspace/videos/sample.jpg\",\n",
    "#     \"/workspace/videos/sample_result.jpg\",\n",
    "#     detector\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## クリーンアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インタラクティブ探索のリソース解放\n",
    "# if 'explorer' in dir():\n",
    "#     explorer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
